{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwings as xw\n",
    "import pandas as pd\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import bs4 as bs\n",
    "import requests \n",
    "import re\n",
    "import yahoo_fin.stock_info as yf\n",
    "import yfinance as yf1\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "list_wrong = []\n",
    "\n",
    "result_PE =pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "    \n",
    "def findata(stock):\n",
    "    global result_PE\n",
    "    global i \n",
    "    i = i + 1\n",
    "    try:\n",
    "        #print(stock)\n",
    "        #爬虫爬取数据\n",
    "        stock1 = stock\n",
    "        stock = stock.replace(\"-\", \".\")\n",
    "        print(i,stock)\n",
    "        url = \"https://www.macrotrends.net/stocks/charts/\"+stock+\"//eps-earnings-per-share-diluted\"\n",
    "        resp = requests.get(url)\n",
    "        soup = bs.BeautifulSoup(resp.text, \"lxml\")\n",
    "        table = soup.findAll('tbody')\n",
    "        tickers = []\n",
    "        tickers1 = []\n",
    "        \n",
    "        \n",
    "        for row in table[2].findAll('tr')[0:]:\n",
    "            ticker = [t.text.strip('$') for t in row.find_all('td')] #去掉$符号\n",
    "            tickers1.append(ticker)\n",
    "        #print(tickers1)\n",
    "\n",
    "        for row in table[1].findAll('tr')[0:]:\n",
    "            ticker = [t.text.strip('$') for t in row.find_all('td')] #去掉$符号\n",
    "            tickers.append(ticker)\n",
    "\n",
    "        #print(tickers)\n",
    "        #计算 EPS_TTM\n",
    "        columns=[\"Date\", \"EPS\"]\n",
    "        df_EPS = pd.DataFrame(data=tickers, columns=columns)\n",
    "        df_EPS['EPS'] = df_EPS['EPS'].astype(float) \n",
    "        df_EPS['EPS_TTM'] = df_EPS['EPS'] + df_EPS['EPS'].shift(-1) + df_EPS['EPS'].shift(-2) + df_EPS['EPS'].shift(-3) \n",
    "        df_EPS.EPS_TTM = df_EPS.EPS_TTM.fillna(-998) #-998表示没有可供计算年EPS的数据\n",
    "        \n",
    "        #根据其它列的条件，增加新列EPS_GRTH\n",
    "        df_EPS.loc[((df_EPS['EPS_TTM'].shift(-4)>0) & (df_EPS['EPS_TTM']>0)),'EPS_TTM_GRTH']=df_EPS['EPS_TTM']/df_EPS['EPS_TTM'].shift(-4) - 1 \n",
    "        df_EPS.loc[((df_EPS['EPS'].shift(-4)>0) & (df_EPS['EPS']>0)),'EPS_GRTH']=df_EPS['EPS']/df_EPS['EPS'].shift(-4) - 1 \n",
    "        \n",
    "        #df_EPS.EPS_TTM_GRTH = df_EPS.EPS_TTM_GRTH.fillna(-999)\n",
    "        #df_EPS.EPS_GRTH = df_EPS.EPS_GRTH.fillna(-999)\n",
    "        \n",
    "        #print(df_EPS)\n",
    "        #增加收入信息\n",
    "        url2 = \"https://www.macrotrends.net/stocks/charts/\"+stock+\"//revenue\"\n",
    "        resp2 = requests.get(url2)\n",
    "        soup2 = bs.BeautifulSoup(resp2.text, \"lxml\")\n",
    "        table = soup2.findAll('tbody')\n",
    "        tickers2 = []\n",
    "        \n",
    "       # print(table[1])\n",
    "        for row in table[1].findAll('tr')[0:]:\n",
    "            \n",
    "            ticker = [t.text.strip('$').replace(',','') for t in row.find_all('td')] #去掉$符号\n",
    "            #print(ticker)\n",
    "            if ticker[1] !='':\n",
    "                #print(ticker[1])\n",
    "                tickers2.append(ticker)\n",
    "        #print(tickers2)\n",
    "             \n",
    "        \n",
    "        columns2=[\"Date\", \"Revenue\"]\n",
    "        df_Revenue = pd.DataFrame(data=tickers2, columns=columns2)\n",
    "        #print(df_Revenue['Revenue'])\n",
    "        df_Revenue['Revenue'] = df_Revenue['Revenue'].astype(float) \n",
    "        #print(2)\n",
    "        df_Revenue['Revenue_TTM'] = df_Revenue['Revenue'] + df_Revenue['Revenue'].shift(-1) + df_Revenue['Revenue'].shift(-2) + df_Revenue['Revenue'].shift(-3) \n",
    "        #print(3)\n",
    "        df_Revenue.Revenue_TTM = df_Revenue.Revenue_TTM.fillna(-998) #-998表示没有可供计算年EPS的数据\n",
    "        \n",
    "        \n",
    "        \n",
    "        #根据其它列的条件，增加新列EPS_GRTH\n",
    "        df_Revenue.loc[((df_Revenue['Revenue_TTM'].shift(-4)>0) & (df_Revenue['Revenue_TTM']>0)),'Revenue_TTM_GRTH']=df_Revenue['Revenue_TTM']/df_Revenue['Revenue_TTM'].shift(-4) - 1 \n",
    "        df_Revenue.loc[((df_Revenue['Revenue'].shift(-4)>0) & (df_Revenue['Revenue']>0)),'Revenue_GRTH']=df_Revenue['Revenue']/df_Revenue['Revenue'].shift(-4) - 1 \n",
    "        \n",
    "        df_Revenue.Revenue_TTM_GRTH = df_Revenue.Revenue_TTM_GRTH.fillna(-999)\n",
    "        df_Revenue.Revenue_GRTH = df_Revenue.Revenue_GRTH.fillna(-999)\n",
    "        \n",
    "        end = datetime.date.today()\n",
    "        start = end - relativedelta(days=10)\n",
    "              \n",
    "        Price = web.get_data_yahoo(stock1,start,end).iloc[-1]['Adj Close']\n",
    "        \n",
    "        #Date = web.get_data_yahoo(stock1,start,end).iloc[-1].idx\n",
    "        \n",
    "        if df_EPS.iloc[0]['EPS_TTM'] > 0:\n",
    "            PE = Price/df_EPS.iloc[0]['EPS_TTM']\n",
    "        else:\n",
    "            PE = 0\n",
    "        \n",
    "        if df_EPS.iloc[0]['EPS_TTM_GRTH'] > 0:\n",
    "            PEG = PE*0.01/df_EPS.iloc[0]['EPS_TTM_GRTH']\n",
    "        else:\n",
    "            PEG = 0\n",
    "                 \n",
    "        result_PE = result_PE.append(pd.DataFrame({'ticker':[stock],\\\n",
    "                                    \n",
    "                                    'PE':[PE],\n",
    "                                    'PEG':[PEG],\n",
    "                                    'Price':[Price],\n",
    "                                    #'Date':[Date],\n",
    "                                    'MarketCap':[tickers1[0][2].strip('B')],\n",
    "                                    'Industry': [tickers1[0][1]],                                                                            \n",
    " \n",
    "                                                          \n",
    "                                    'Q12':[df_EPS.iloc[11]['Date']],\n",
    "                                    'Q11':[df_EPS.iloc[10]['Date']],\n",
    "                                    'Q10':[df_EPS.iloc[9]['Date']],\n",
    "                                    'Q9':[df_EPS.iloc[8]['Date']],\n",
    "                                    'Q8':[df_EPS.iloc[7]['Date']],\n",
    "                                    'Q7':[df_EPS.iloc[6]['Date']],\n",
    "                                    'Q6':[df_EPS.iloc[5]['Date']],\n",
    "                                    'Q5':[df_EPS.iloc[4]['Date']],\n",
    "                                    'Q4':[df_EPS.iloc[3]['Date']],\n",
    "                                    'Q3':[df_EPS.iloc[2]['Date']],\n",
    "                                    'Q2':[df_EPS.iloc[1]['Date']],\n",
    "                                    'Q1':[df_EPS.iloc[0]['Date']],      \n",
    "                                                   \n",
    "                                    'EPS12':[df_EPS.iloc[11]['EPS']],\n",
    "                                    'EPS11':[df_EPS.iloc[10]['EPS']],                                              \n",
    "                                    'EPS10':[df_EPS.iloc[9]['EPS']],\n",
    "                                    'EPS9':[df_EPS.iloc[8]['EPS']],\n",
    "                                    'EPS8':[df_EPS.iloc[7]['EPS']],\n",
    "                                    'EPS7':[df_EPS.iloc[6]['EPS']],                                              \n",
    "                                    'EPS6':[df_EPS.iloc[5]['EPS']],\n",
    "                                    'EPS5':[df_EPS.iloc[4]['EPS']],\n",
    "                                    'EPS4':[df_EPS.iloc[3]['EPS']],\n",
    "                                    'EPS3':[df_EPS.iloc[2]['EPS']],                                              \n",
    "                                    'EPS2':[df_EPS.iloc[1]['EPS']],\n",
    "                                    'EPS1':[df_EPS.iloc[0]['EPS']],\n",
    "                                                   \n",
    "                                    'EPS_GRTH12':[df_EPS.iloc[11]['EPS_GRTH']],\n",
    "                                    'EPS_GRTH11':[df_EPS.iloc[10]['EPS_GRTH']],                                              \n",
    "                                    'EPS_GRTH10':[df_EPS.iloc[9]['EPS_GRTH']],\n",
    "                                    'EPS_GRTH9':[df_EPS.iloc[8]['EPS_GRTH']], \n",
    "                                    'EPS_GRTH8':[df_EPS.iloc[7]['EPS_GRTH']],\n",
    "                                    'EPS_GRTH7':[df_EPS.iloc[6]['EPS_GRTH']],                                              \n",
    "                                    'EPS_GRTH6':[df_EPS.iloc[5]['EPS_GRTH']],\n",
    "                                    'EPS_GRTH5':[df_EPS.iloc[4]['EPS_GRTH']], \n",
    "                                    'EPS_GRTH4':[df_EPS.iloc[3]['EPS_GRTH']],\n",
    "                                    'EPS_GRTH3':[df_EPS.iloc[2]['EPS_GRTH']],                                              \n",
    "                                    'EPS_GRTH2':[df_EPS.iloc[1]['EPS_GRTH']],\n",
    "                                    'EPS_GRTH1':[df_EPS.iloc[0]['EPS_GRTH']], \n",
    "                                                   \n",
    "                                    'EPS_TTM12':[df_EPS.iloc[11]['EPS_TTM']],\n",
    "                                    'EPS_TTM11':[df_EPS.iloc[10]['EPS_TTM']],                                              \n",
    "                                    'EPS_TTM10':[df_EPS.iloc[9]['EPS_TTM']],\n",
    "                                    'EPS_TTM9':[df_EPS.iloc[8]['EPS_TTM']],  \n",
    "                                    'EPS_TTM8':[df_EPS.iloc[7]['EPS_TTM']],\n",
    "                                    'EPS_TTM7':[df_EPS.iloc[6]['EPS_TTM']],                                              \n",
    "                                    'EPS_TTM6':[df_EPS.iloc[5]['EPS_TTM']],\n",
    "                                    'EPS_TTM5':[df_EPS.iloc[4]['EPS_TTM']],  \n",
    "                                    'EPS_TTM4':[df_EPS.iloc[3]['EPS_TTM']],\n",
    "                                    'EPS_TTM3':[df_EPS.iloc[2]['EPS_TTM']],                                              \n",
    "                                    'EPS_TTM2':[df_EPS.iloc[1]['EPS_TTM']],\n",
    "                                    'EPS_TTM1':[df_EPS.iloc[0]['EPS_TTM']],  \n",
    "                                                   \n",
    "                                    'EPS_TTM_GRTH12':[df_EPS.iloc[11]['EPS_TTM_GRTH']],\n",
    "                                    'EPS_TTM_GRTH11':[df_EPS.iloc[10]['EPS_TTM_GRTH']],                                              \n",
    "                                    'EPS_TTM_GRTH10':[df_EPS.iloc[9]['EPS_TTM_GRTH']],\n",
    "                                    'EPS_TTM_GRTH9':[df_EPS.iloc[8]['EPS_TTM_GRTH']],  \n",
    "                                    'EPS_TTM_GRTH8':[df_EPS.iloc[7]['EPS_TTM_GRTH']],\n",
    "                                    'EPS_TTM_GRTH7':[df_EPS.iloc[6]['EPS_TTM_GRTH']],                                              \n",
    "                                    'EPS_TTM_GRTH6':[df_EPS.iloc[5]['EPS_TTM_GRTH']],\n",
    "                                    'EPS_TTM_GRTH5':[df_EPS.iloc[4]['EPS_TTM_GRTH']],\n",
    "                                    'EPS_TTM_GRTH4':[df_EPS.iloc[3]['EPS_TTM_GRTH']],\n",
    "                                    'EPS_TTM_GRTH3':[df_EPS.iloc[2]['EPS_TTM_GRTH']],                                              \n",
    "                                    'EPS_TTM_GRTH2':[df_EPS.iloc[1]['EPS_TTM_GRTH']],\n",
    "                                    'EPS_TTM_GRTH1':[df_EPS.iloc[0]['EPS_TTM_GRTH']],\n",
    "                                                   \n",
    "                                    'Revenue12':[df_Revenue.iloc[11]['Revenue']],\n",
    "                                    'Revenue11':[df_Revenue.iloc[10]['Revenue']],                                              \n",
    "                                    'Revenue10':[df_Revenue.iloc[9]['Revenue']],\n",
    "                                    'Revenue9':[df_Revenue.iloc[8]['Revenue']],\n",
    "                                    'Revenue8':[df_Revenue.iloc[7]['Revenue']],\n",
    "                                    'Revenue7':[df_Revenue.iloc[6]['Revenue']],                                              \n",
    "                                    'Revenue6':[df_Revenue.iloc[5]['Revenue']],\n",
    "                                    'Revenue5':[df_Revenue.iloc[4]['Revenue']],\n",
    "                                    'Revenue4':[df_Revenue.iloc[3]['Revenue']],\n",
    "                                    'Revenue3':[df_Revenue.iloc[2]['Revenue']],                                              \n",
    "                                    'Revenue2':[df_Revenue.iloc[1]['Revenue']],\n",
    "                                    'Revenue1':[df_Revenue.iloc[0]['Revenue']],\n",
    "                                                   \n",
    "                                    'Revenue_GRTH12':[df_Revenue.iloc[11]['Revenue_GRTH']],\n",
    "                                    'Revenue_GRTH11':[df_Revenue.iloc[10]['Revenue_GRTH']],                                         \n",
    "                                    'Revenue_GRTH10':[df_Revenue.iloc[9]['Revenue_GRTH']],\n",
    "                                    'Revenue_GRTH9':[df_Revenue.iloc[8]['Revenue_GRTH']],             \n",
    "                                    'Revenue_GRTH8':[df_Revenue.iloc[7]['Revenue_GRTH']],\n",
    "                                    'Revenue_GRTH7':[df_Revenue.iloc[6]['Revenue_GRTH']],                                              \n",
    "                                    'Revenue_GRTH6':[df_Revenue.iloc[5]['Revenue_GRTH']],\n",
    "                                    'Revenue_GRTH5':[df_Revenue.iloc[4]['Revenue_GRTH']],              \n",
    "                                    'Revenue_GRTH4':[df_Revenue.iloc[3]['Revenue_GRTH']],\n",
    "                                    'Revenue_GRTH3':[df_Revenue.iloc[2]['Revenue_GRTH']],                                              \n",
    "                                    'Revenue_GRTH2':[df_Revenue.iloc[1]['Revenue_GRTH']],\n",
    "                                    'Revenue_GRTH1':[df_Revenue.iloc[0]['Revenue_GRTH']],                             \n",
    "                                               \n",
    "                                                  \n",
    "                                    'Revenue_TTM12':[df_Revenue.iloc[11]['Revenue_TTM']],\n",
    "                                    'Revenue_TTM11':[df_Revenue.iloc[10]['Revenue_TTM']],                                              \n",
    "                                    'Revenue_TTM10':[df_Revenue.iloc[9]['Revenue_TTM']],\n",
    "                                    'Revenue_TTM9':[df_Revenue.iloc[8]['Revenue_TTM']],  \n",
    "                                    'Revenue_TTM8':[df_Revenue.iloc[7]['Revenue_TTM']],\n",
    "                                    'Revenue_TTM7':[df_Revenue.iloc[6]['Revenue_TTM']],                                              \n",
    "                                    'Revenue_TTM6':[df_Revenue.iloc[5]['Revenue_TTM']],\n",
    "                                    'Revenue_TTM5':[df_Revenue.iloc[4]['Revenue_TTM']],  \n",
    "                                    'Revenue_TTM4':[df_Revenue.iloc[3]['Revenue_TTM']],\n",
    "                                    'Revenue_TTM3':[df_Revenue.iloc[2]['Revenue_TTM']],                                              \n",
    "                                    'Revenue_TTM2':[df_Revenue.iloc[1]['Revenue_TTM']],\n",
    "                                    'Revenue_TTM1':[df_Revenue.iloc[0]['Revenue_TTM']],  \n",
    "                                                   \n",
    "                                    'Revenue_TTM_GRTH12':[df_Revenue.iloc[11]['Revenue_TTM_GRTH']],\n",
    "                                    'Revenue_TTM_GRTH11':[df_Revenue.iloc[10]['Revenue_TTM_GRTH']],                                              \n",
    "                                    'Revenue_TTM_GRTH10':[df_Revenue.iloc[9]['Revenue_TTM_GRTH']],\n",
    "                                    'Revenue_TTM_GRTH9':[df_Revenue.iloc[8]['Revenue_TTM_GRTH']], \n",
    "                                    'Revenue_TTM_GRTH8':[df_Revenue.iloc[7]['Revenue_TTM_GRTH']],\n",
    "                                    'Revenue_TTM_GRTH7':[df_Revenue.iloc[6]['Revenue_TTM_GRTH']],                                              \n",
    "                                    'Revenue_TTM_GRTH6':[df_Revenue.iloc[5]['Revenue_TTM_GRTH']],\n",
    "                                    'Revenue_TTM_GRTH5':[df_Revenue.iloc[4]['Revenue_TTM_GRTH']], \n",
    "                                    'Revenue_TTM_GRTH4':[df_Revenue.iloc[3]['Revenue_TTM_GRTH']],\n",
    "                                    'Revenue_TTM_GRTH3':[df_Revenue.iloc[2]['Revenue_TTM_GRTH']],                                              \n",
    "                                    'Revenue_TTM_GRTH2':[df_Revenue.iloc[1]['Revenue_TTM_GRTH']],\n",
    "                                    'Revenue_TTM_GRTH1':[df_Revenue.iloc[0]['Revenue_TTM_GRTH']], \n",
    "                                                 \n",
    "                                                                       \n",
    "                                    'Intro':[tickers1[1][0][1:-1]]\n",
    "                                         \n",
    "                                     }),ignore_index=True,sort=False) \n",
    "        #print(tickers1[1])\n",
    "       \n",
    "    except:\n",
    "        print(stock,'.....................wrong.....................')\n",
    "        list_wrong.append(stock)\n",
    "        \n",
    "df_p_e_f2 =pd.DataFrame()\n",
    "\n",
    "list_wrong1 = []\n",
    "def trace_pe(stock):\n",
    "    \n",
    "    global df_p_e_f2\n",
    "    try:\n",
    "        #print(stock)\n",
    "        #爬虫爬取数据\n",
    "        url = \"https://www.macrotrends.net/stocks/charts/\"+stock+\"//eps-earnings-per-share-diluted\"\n",
    "        resp = requests.get(url)\n",
    "        soup = bs.BeautifulSoup(resp.text, \"lxml\")\n",
    "        table = soup.findAll('tbody')\n",
    "        tickers = []\n",
    "\n",
    "        for row in table[1].findAll('tr')[0:]:\n",
    "            ticker = [t.text.strip('$') for t in row.find_all('td')] #去掉$符号\n",
    "            tickers.append(ticker)\n",
    "\n",
    "        #print(tickers)\n",
    "        #计算 EPS_TTM\n",
    "        columns=[\"Date\", \"EPS\"]\n",
    "        df_EPS = pd.DataFrame(data=tickers, columns=columns)\n",
    "        df_EPS['EPS'] = df_EPS['EPS'].astype(float) \n",
    "        df_EPS['EPS_TTM'] = df_EPS['EPS'] + df_EPS['EPS'].shift(-1) + df_EPS['EPS'].shift(-2) + df_EPS['EPS'].shift(-3) \n",
    "        df_EPS.EPS_TTM = df_EPS.EPS_TTM.fillna(-998) #-998表示没有可供计算年EPS的数据\n",
    "        \n",
    "        #根据其它列的条件，增加新列EPS_GRTH\n",
    "        df_EPS.loc[((df_EPS['EPS_TTM'].shift(-4)>0) & (df_EPS['EPS_TTM']>0)),'EPS_GRTH']=df_EPS['EPS_TTM']/df_EPS['EPS_TTM'].shift(-4) - 1 \n",
    "        df_EPS.EPS_GRTH = df_EPS.EPS_GRTH.fillna(-999)\n",
    "        \n",
    "        \n",
    "        df_EPS['Date'] = pd.to_datetime(df_EPS['Date'])\n",
    "        df_EPS.set_index('Date', inplace=True) \n",
    "        \n",
    "        #print(df_EPS)\n",
    "        #下载股价数据\n",
    "        #start = datetime.datetime(2005,4,1)\n",
    "        end = datetime.date.today()\n",
    "        start = end - relativedelta(years=3)\n",
    "        df = web.get_data_yahoo(stock,start,end)\n",
    "        df1 = df[['Volume','Adj Close']]\n",
    "        \n",
    "        #print(df1.head(10))\n",
    "        #拼表#填充\n",
    "        df_p_e = pd.concat([df1,df_EPS],axis=1)            \n",
    "        df_p_e_f = df_p_e.fillna(method='pad')\n",
    "        \n",
    "        #print(df_p_e_f.head(10))\n",
    "        \n",
    "        #计算PE、PEG、分位数、均值\n",
    "        df_p_e_f.loc[df_p_e_f['EPS_TTM']>0,'PE']=df_p_e_f['Adj Close']/df_p_e_f['EPS_TTM']\n",
    "        \n",
    "        df_p_e_f['PE_Median_500'] = df_p_e_f.PE.rolling(500).quantile(.55)\n",
    "        df_p_e_f['PE_quant10_500'] = df_p_e_f.PE.rolling(500).quantile(.1)\n",
    "        df_p_e_f['PE_quant90_500'] = df_p_e_f.PE.rolling(500).quantile(0.9)\n",
    "        df_p_e_f['PE_mean_500'] = df_p_e_f.PE.rolling(500).mean()\n",
    "        \n",
    "        df_p_e_f.loc[df_p_e_f['EPS_GRTH']>0,'PEG']=df_p_e_f['PE']*0.01/df_p_e_f['EPS_GRTH']\n",
    "        \n",
    "        #print(df_p_e_f.head(10))\n",
    "        #倒序\n",
    "        df_p_e_f1 = df_p_e_f.sort_index(ascending=False,axis=0)\n",
    "        \n",
    "        #print(df_p_e_f1.head(10))\n",
    "        \n",
    "        #切片最近10年数据\n",
    "        df_p_e_f2 = df_p_e_f1.iloc[:250].sort_index(ascending=True,axis=0)\n",
    "        \n",
    "        wb = xw.Book('C:/Users/zty1979/Documents/美股/dashboard.xlsx')\n",
    "        \n",
    "        sht = wb.sheets[stock]\n",
    "            \n",
    "        sht.range('Z1').value = df_p_e_f2\n",
    " \n",
    "    except:\n",
    "        print(stock,'.....................wrong.....................')\n",
    "        list_wrong1.append(stock)\n",
    "        \n",
    "wb = xw.Book('C:/Users/zty1979/Documents/美股/dashboard.xlsx')\n",
    "sht_list = wb.sheets['list']\n",
    "sht_data = wb.sheets['data']\n",
    "sht_template = wb.sheets['template']\n",
    "\n",
    "list_tickers = sht_list.range('A2').expand().value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取现有sheet名称中的股票名称\n",
    "x = []# 创建空列表\n",
    "num =len(wb.sheets)#获取sheet个数\n",
    "for j in range(0,num):\n",
    "    sht = wb.sheets[j]\n",
    "    x.append(sht.name)\n",
    "    j +=1          # 计数数量自加1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除多余的sheet\n",
    "for ticker in x:\n",
    "     if (ticker not in list_tickers) and (ticker not in ['list','data','template'])\n",
    "         wb.sheets[ticker].delete()\n",
    "            #sht.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加列表中的sheet\n",
    "for ticker in list_tickers:\n",
    "    if ticker not in x:\n",
    "        sht_template.api.Copy(Before=sht_template.api)\n",
    "        wb.sheets['template (2)'].api.Name = ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123  TMO\n",
      " 4 GOOGLALB\n",
      "\n",
      "NVDA\n",
      "5 MSFT\n",
      "6 NUE\n",
      "7 WIRE\n",
      "8 LRCX\n",
      "9 QRVO\n",
      "10 STLD\n",
      "11 TSLA\n",
      "12 AMD\n",
      "13 TSM\n",
      "14 PYPL\n",
      "15 MOS\n",
      "16 NFLX\n"
     ]
    }
   ],
   "source": [
    "# 导入财务数据\n",
    "tickers = list_tickers \n",
    "result_PE=result_PE.drop(index=result_PE.index)\n",
    "pool = ThreadPool()\n",
    "pool.map(findata, tickers)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = list_wrong\n",
    "#tickers = ['AAPL','AMD','BA','V']\n",
    "#tickers = ['JPM']\n",
    "list_wrong = []\n",
    "#result_PE=result_PE.drop(index=result_PE.index)\n",
    "pool = ThreadPool()\n",
    "pool.map(findata, tickers)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht_data.range('A1').value = result_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in list_tickers:\n",
    "    trace_pe(ticker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
